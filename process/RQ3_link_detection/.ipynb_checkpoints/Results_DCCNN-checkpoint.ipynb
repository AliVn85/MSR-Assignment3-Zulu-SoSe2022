{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1cdf39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Notebook.\n"
     ]
    }
   ],
   "source": [
    "#Needed Modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Starting Notebook.\")\n",
    "\n",
    "sns.set(font_scale = 1.25)\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ae8f562",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCES = ['Apache', 'Hyperledger', 'IntelDAOS', \n",
    "           'JFrog', 'Jira', 'JiraEcosystem', \n",
    "           'MariaDB', 'MongoDB', 'Qt', \n",
    "           'RedHat', 'Sakai', 'SecondLife', \n",
    "           'Sonatype', 'Spring']\n",
    "#Mindville\n",
    "CONFIG = ['R_LTvNL', 'R_LTvNLOL', 'R_LTOLvNL']\n",
    "LT = 'Duplication'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c4404e",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d10101aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_linktypes(SOURCE):\n",
    "    #Loading Issues\n",
    "    filename = '../data/crawl/issues_'+SOURCE.lower()+'.csv'\n",
    "    issues = pd.read_csv(filename, encoding=\"UTF-8\", low_memory=False, sep=';')\n",
    "    \n",
    "    issue_set = set(issues['issue_id'])\n",
    "        \n",
    "    #Loading Links\n",
    "    filename = '../data/crawl/clean_links_'+SOURCE.lower()+'.csv'\n",
    "    links = pd.read_csv(filename, encoding=\"UTF-8\", low_memory=False, index_col=0, sep=';')\n",
    "\n",
    "    link_set = set(links['issue_id_1']).union(set(links['issue_id_2']))\n",
    "\n",
    "    num_dups = len(links[links['linktype']=='Duplicate'])\n",
    "        \n",
    "    return len(issues), len(links), len(links.linktype.unique()), round(len(link_set)/len(issue_set), 3), num_dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d84bd7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "overview = pd.DataFrame(columns = ['Project', '#Issues', '#Links', '#Linktypes', '%IssuesWithLinks', '#NumDups'])\n",
    "j=0\n",
    "for s in SOURCES:\n",
    "    i, l, ltu, pi, nd = print_linktypes(s)\n",
    "    \n",
    "    if s == 'JiraEcosystem':\n",
    "        s = 'JiraEco.'\n",
    "    \n",
    "    overview.loc[j]=[s, i, l, ltu, pi, nd]\n",
    "    \n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2fc01d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Project</th>\n",
       "      <th>#Issues</th>\n",
       "      <th>#Links</th>\n",
       "      <th>#Linktypes</th>\n",
       "      <th>%IssuesWithLinks</th>\n",
       "      <th>#NumDups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apache</td>\n",
       "      <td>1014926</td>\n",
       "      <td>255767</td>\n",
       "      <td>22</td>\n",
       "      <td>0.285</td>\n",
       "      <td>25925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RedHat</td>\n",
       "      <td>353000</td>\n",
       "      <td>119669</td>\n",
       "      <td>21</td>\n",
       "      <td>0.392</td>\n",
       "      <td>5913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jira</td>\n",
       "      <td>274545</td>\n",
       "      <td>99819</td>\n",
       "      <td>19</td>\n",
       "      <td>0.467</td>\n",
       "      <td>21685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Qt</td>\n",
       "      <td>148579</td>\n",
       "      <td>40105</td>\n",
       "      <td>12</td>\n",
       "      <td>0.302</td>\n",
       "      <td>4243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MongoDB</td>\n",
       "      <td>137172</td>\n",
       "      <td>63821</td>\n",
       "      <td>15</td>\n",
       "      <td>0.452</td>\n",
       "      <td>8587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sonatype</td>\n",
       "      <td>87284</td>\n",
       "      <td>4465</td>\n",
       "      <td>11</td>\n",
       "      <td>0.070</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Spring</td>\n",
       "      <td>69156</td>\n",
       "      <td>14462</td>\n",
       "      <td>9</td>\n",
       "      <td>0.256</td>\n",
       "      <td>1745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sakai</td>\n",
       "      <td>50550</td>\n",
       "      <td>19803</td>\n",
       "      <td>8</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>JiraEco.</td>\n",
       "      <td>41866</td>\n",
       "      <td>11398</td>\n",
       "      <td>20</td>\n",
       "      <td>0.330</td>\n",
       "      <td>1741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MariaDB</td>\n",
       "      <td>31229</td>\n",
       "      <td>14618</td>\n",
       "      <td>8</td>\n",
       "      <td>0.445</td>\n",
       "      <td>1374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hyperledger</td>\n",
       "      <td>28146</td>\n",
       "      <td>16304</td>\n",
       "      <td>8</td>\n",
       "      <td>0.549</td>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JFrog</td>\n",
       "      <td>15535</td>\n",
       "      <td>3229</td>\n",
       "      <td>11</td>\n",
       "      <td>0.286</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IntelDAOS</td>\n",
       "      <td>9474</td>\n",
       "      <td>2599</td>\n",
       "      <td>13</td>\n",
       "      <td>0.308</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SecondLife</td>\n",
       "      <td>1867</td>\n",
       "      <td>631</td>\n",
       "      <td>6</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Project  #Issues  #Links  #Linktypes  %IssuesWithLinks  #NumDups\n",
       "0        Apache  1014926  255767          22             0.285     25925\n",
       "9        RedHat   353000  119669          21             0.392      5913\n",
       "4          Jira   274545   99819          19             0.467     21685\n",
       "8            Qt   148579   40105          12             0.302      4243\n",
       "7       MongoDB   137172   63821          15             0.452      8587\n",
       "12     Sonatype    87284    4465          11             0.070       342\n",
       "13       Spring    69156   14462           9             0.256      1745\n",
       "10        Sakai    50550   19803           8             0.424         0\n",
       "5      JiraEco.    41866   11398          20             0.330      1741\n",
       "6       MariaDB    31229   14618           8             0.445      1374\n",
       "1   Hyperledger    28146   16304           8             0.549       638\n",
       "3         JFrog    15535    3229          11             0.286       643\n",
       "2     IntelDAOS     9474    2599          13             0.308       252\n",
       "11   SecondLife     1867     631           6             0.399         0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview.sort_values(by=['#Issues'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee50d6bf",
   "metadata": {},
   "source": [
    "## Loading Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "authentic-macedonia",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results_v1/dccnn_apache_Duplication_R_LTvNL_metrics.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m CONFIG:\n\u001b[0;32m      6\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults_v1/dccnn_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39ms\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mLT\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mc\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_metrics.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 7\u001b[0m     metrics_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUTF-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     LT_mets \u001b[38;5;241m=\u001b[39m metrics_df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist()[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m     10\u001b[0m     NL_mets \u001b[38;5;241m=\u001b[39m metrics_df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist()[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas-1.4.3-py3.10-win-amd64.egg\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas-1.4.3-py3.10-win-amd64.egg\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas-1.4.3-py3.10-win-amd64.egg\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas-1.4.3-py3.10-win-amd64.egg\\pandas\\io\\parsers\\readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 934\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas-1.4.3-py3.10-win-amd64.egg\\pandas\\io\\parsers\\readers.py:1218\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1218\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1228\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1229\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas-1.4.3-py3.10-win-amd64.egg\\pandas\\io\\common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    785\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 786\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    794\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    795\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results_v1/dccnn_apache_Duplication_R_LTvNL_metrics.csv'"
     ]
    }
   ],
   "source": [
    "valid_projects = []\n",
    "\n",
    "for s in SOURCES:\n",
    "    if (s == \"MariaDB\"):\n",
    "        valid = True\n",
    "        for c in CONFIG:\n",
    "            filename = 'results/dccnn_'+s.lower()+'_'+LT+'_'+c+'_metrics.csv'\n",
    "            metrics_df = pd.read_csv(filename, encoding=\"UTF-8\", low_memory=False)\n",
    "\n",
    "            LT_mets = metrics_df.iloc[0].values.tolist()[1:]\n",
    "            NL_mets = metrics_df.iloc[1].values.tolist()[1:]\n",
    "            OL_mets = metrics_df.iloc[2].values.tolist()[1:]\n",
    "            valid = valid and not(np.isnan(LT_mets + OL_mets + NL_mets).any())\n",
    "\n",
    "        if valid:\n",
    "            valid_projects.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206da8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-telescope",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tpfptnfn(conf_mat):\n",
    "    \n",
    "    tp = conf_mat.loc[\"DUPLICATION\"][1] \n",
    "    fn = conf_mat.loc[\"DUPLICATION\"][0] \n",
    "    fp = conf_mat.loc[\"NON-LINKS\"][1] \n",
    "    tn = conf_mat.loc[\"NON-LINKS\"][0] \n",
    "    \n",
    "    return tp, fp, tn, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(c, trad):\n",
    "    avg_d_pre = []\n",
    "    avg_d_rec = []\n",
    "    avg_d_f1 = []\n",
    "\n",
    "    avg_nl_pre = []\n",
    "    avg_nl_rec = []\n",
    "    avg_nl_f1 = []\n",
    "\n",
    "    avg_ol_0 = []\n",
    "    avg_ol_1 = []\n",
    "\n",
    "    avg_acc = []\n",
    "\n",
    "    avg_pre = []\n",
    "    avg_rec = []\n",
    "    avg_f1 = []\n",
    "\n",
    "    for s in valid_projects:\n",
    "#         print(s.upper())\n",
    "        filename = 'results/dccnn_'+s.lower()+'_'+LT+'_'+c+'_confmat.csv'\n",
    "        confmat_df = pd.read_csv(filename, encoding=\"UTF-8\", low_memory=False, index_col='Class')\n",
    "        confmat_df = pd.DataFrame(confmat_df.values, index=['DUPLICATION', 'OTHER-LINKS', 'NON-LINKS'])\n",
    "\n",
    "        avg_ol_0.append((confmat_df.transpose()/confmat_df.sum(axis=1)).loc[0][\"OTHER-LINKS\"])\n",
    "        avg_ol_1.append((confmat_df.transpose()/confmat_df.sum(axis=1)).loc[1][\"OTHER-LINKS\"])\n",
    "\n",
    "#         print(\"OL 0: \"+ str(np.round((confmat_df.transpose()/confmat_df.sum(axis=1)).loc['0'][\"OTHER-LINKS\"], 3)))\n",
    "#         print(\"OL 1: \"+ str(np.round((confmat_df.transpose()/confmat_df.sum(axis=1)).loc['1'][\"OTHER-LINKS\"], 3)))\n",
    "        \n",
    "        if not trad:\n",
    "            if c == 'R_LTOLvNL':\n",
    "                new_confmat = [[confmat_df.loc[\"DUPLICATION\"][0]+confmat_df.loc[\"OTHER-LINKS\"][0], \n",
    "                                confmat_df.loc[\"DUPLICATION\"][1]+confmat_df.loc[\"OTHER-LINKS\"][1]],\n",
    "                               [confmat_df.loc[\"NON-LINKS\"][0],\n",
    "                                confmat_df.loc[\"NON-LINKS\"][1]]]\n",
    "                new_confmat_df = pd.DataFrame(new_confmat, index=['DUPLICATION', 'NON-LINKS'])\n",
    "            else:\n",
    "                new_confmat = [[confmat_df.loc[\"DUPLICATION\"][0], \n",
    "                                confmat_df.loc[\"DUPLICATION\"][1]],\n",
    "                               [confmat_df.loc[\"OTHER-LINKS\"][0]+confmat_df.loc[\"NON-LINKS\"][0],\n",
    "                                confmat_df.loc[\"OTHER-LINKS\"][1]+confmat_df.loc[\"NON-LINKS\"][1]]]\n",
    "                new_confmat_df = pd.DataFrame(new_confmat, index=['DUPLICATION', 'NON-LINKS'])\n",
    "            confmat_df = new_confmat_df\n",
    "\n",
    "        tp, fp, tn, fn = get_tpfptnfn(confmat_df)\n",
    "        \n",
    "        d_pre = tp/(tp+fp)\n",
    "        d_rec = tp/(tp+fn)\n",
    "        d_f1 = 2*(d_pre*d_rec)/(d_pre+d_rec)\n",
    "\n",
    "        avg_d_pre.append(d_pre)\n",
    "        avg_d_rec.append(d_rec)\n",
    "        avg_d_f1.append(d_f1)\n",
    "\n",
    "        nl_pre = tn/(tn+fn)\n",
    "        nl_rec = tn/(tn+fp)\n",
    "        nl_f1 = 2*(nl_pre*nl_rec)/(nl_pre+nl_rec)\n",
    "\n",
    "        avg_nl_pre.append(nl_pre)\n",
    "        avg_nl_rec.append(nl_rec)\n",
    "        avg_nl_f1.append(nl_f1)\n",
    "\n",
    "        pre = (d_pre+nl_pre)/2\n",
    "        rec = (d_rec+nl_rec)/2\n",
    "        f1 = 2*(pre*rec)/(pre+rec)\n",
    "        \n",
    "        avg_pre.append(pre)\n",
    "        avg_rec.append(rec)\n",
    "        avg_f1.append(f1)\n",
    "        \n",
    "        acc = (tp+tn)/(tp+fp+fn+tn)\n",
    "\n",
    "        avg_acc.append(acc)\n",
    "\n",
    "    print(\"+++++++++++++++++\")\n",
    "    print(\"ACC: \"+str(round(np.mean(avg_acc),2)))\n",
    "    print(\"+++++++++++++++++\")\n",
    "    print(\"PRE: \"+str(round(np.mean(avg_pre),2)))\n",
    "    print(\"REC: \"+str(round(np.mean(avg_rec),2)))\n",
    "    print(\"F1: \"+str(round(np.mean(avg_f1),2)))\n",
    "    print(\"+++++++++++++++++\")\n",
    "    print(\"D PRE: \"+str(round(np.mean(avg_d_pre),2)))\n",
    "    print(\"D REC: \"+str(round(np.mean(avg_d_rec),2)))\n",
    "    print(\"D F1: \"+str(round(np.mean(avg_d_f1),2)))\n",
    "    print(\"+++++++++++++++++\")\n",
    "    print(\"NL PRE: \"+str(round(np.mean(avg_nl_pre),2)))\n",
    "    print(\"NL REC: \"+str(round(np.mean(avg_nl_rec),2)))\n",
    "    print(\"NL F1: \"+str(round(np.mean(avg_nl_f1),2)))\n",
    "    print(\"+++++++++++++++++\")\n",
    "    print(\"OL 0: \"+str(round(np.mean(avg_ol_0),2)))\n",
    "    print(\"OL 1: \"+str(round(np.mean(avg_ol_1),2)))\n",
    "\n",
    "    print(\"OL STD: \"+str(round(np.std(avg_ol_0),2)))\n",
    "    \n",
    "    res_dict = {\n",
    "            'ACC' : avg_acc,\n",
    "            'Pre': avg_pre,\n",
    "            'Rec': avg_rec,\n",
    "            'F1': avg_f1,\n",
    "            'D_Pre': avg_d_pre,\n",
    "            'D_Rec': avg_d_rec,\n",
    "            'D_F1': avg_d_f1,\n",
    "            'NL_Pre': avg_nl_pre,\n",
    "            'NL_Rec': avg_nl_rec,\n",
    "            'NL_F1': avg_nl_f1,\n",
    "            'OL_Corr': avg_ol_0,\n",
    "          }\n",
    "\n",
    "    res_data= pd.DataFrame(res_dict, index=[valid_projects])\n",
    "    \n",
    "    return res_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-acceptance",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results('R_LTvNL', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-horizontal",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results('R_LTvNL', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-bhutan",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results('R_LTvNLOL', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-meaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results('R_LTvNLOL', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results('R_LTOLvNL', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-skirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results('R_LTOLvNL', False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
